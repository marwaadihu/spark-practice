http://arun-teaches-u-tech.blogspot.com/p/cca-175-hadoop-and-spark-developer-exam_28.html

=================================================================================
1. Import all tables from mysql database into hdfs as avro data files. use compression and the compression codec should be snappy. data warehouse directory should be retail_stage.db

sqoop import-all-tables \
--connect jdbc:mysql://ms.itversity.com/retail_db \
--username retail_user \
--password itversity \
--as-avrodatafile \
--autoreset-to-one-mapper \
--warehouse-dir /user/saurinchauhan/anilagrawal/cloudera/problem3/retail_stage.db \
--compress \
--compression-codec org.apache.hadoop.io.compress.SnappyCodec

=================================================================================
2. Create a metastore table that should point to the orders data imported by sqoop job above. Name the table orders_sqoop. 

# get one file to local system
hadoop fs -get /user/saurinchauhan/anilagrawal/cloudera/problem3/retail_stage.db/orders/part-m-00000.avro

# create schema using avro-tools
avro-tools getschema part-m-00000.avro > orders.avsc

# create appropriate dir and copy schema file i.e. orders.avsc
hadoop fs -mkdir /user/saurinchauhan/hive
hadoop fs -mkdir /user/saurinchauhan/hive/schemas
hadoop fs -mkdir /user/saurinchauhan/hive/schemas/orders
hadoop fs -copyFromLocal orders.avsc /user/saurinchauhan/hive/schemas/orders

# launch hive and create external table
create external table orders_sqoop
  stored as avro
  location '/user/saurinchauhan/anilagrawal/cloudera/problem3/retail_stage.db/orders'
  tblproperties ('avro.schema.url'='/user/saurinchauhan/hive/schema/orders/orders.avsc');

=================================================================================
3. Write query in hive that shows all orders belonging to a certain day. This day is when the most orders were placed. select data from orders_sqoop. 

select * from orders_sqoop where order_date in (select x.order_date from (select order_date, count(order_id) as total_orders from orders_sqoop group by order_date order by total_orders desc limit 1) as x);

=================================================================================
4. query table in impala that shows all orders belonging to a certain day. This day is when the most orders were placed. select data from order_sqoop. 

=================================================================================
5. Now create a table named retail.orders_avro in hive stored as avro, the table should have same table definition as order_sqoop. Additionally, this new table should be partitioned by the order month i.e -> year-order_month.(example: 2014-01)

create table orders_avro(
  order_id int,
  order_date date,
  order_customer_id int,
  order_status string)
  partitioned by (order_month string)
  stored as avro;

=================================================================================
6. Load data into orders_avro table from orders_sqoop table.

set hive.exec.dynamic.partition.mode=nonstrict

insert overwrite table orders_avro partition (order_month) select order_id, to_date(from_unixtime(cast(order_date/1000 as int))), order_customer_id, order_status, substr(from_unixtime(cast(order_date/1000 as int)),1,7) as order_month from orders_sqoop;

=================================================================================
7. Write query in hive that shows all orders belonging to a certain day. This day is when the most orders were placed. select data from orders_avro

select * from orders_avro where order_date in (select x.order_date from (select order_date, count(order_id) as total_orders from orders_avro group by order_date order by total_orders desc limit 1) as x);

=================================================================================
8. evolve the avro schema related to orders_sqoop table by adding more fields named (order_style String, order_zone Integer)

describe formatted orders_sqoop;

hadoop fs -get /user/saurinchauhan/hive/schema/orders/orders.avsc

vi orders.avsc

hadoop fs -rm /user/saurinchauhan/hive/schema/orders/orders.avsc

hadoop fs -copyFromLocal orders.avsc /user/saurinchauhan/hive/schema/orders/orders.avsc

=================================================================================
9. insert two more records into orders_sqoop table. 

insert into orders_sqoop values (99999,1406088000000,5533,'COMPLETE','test',9);
insert into orders_sqoop values (99998,1406088000000,5533,'COMPLETE','test-1',8);

=================================================================================
10. Write query in hive that shows all orders belonging to a certain day. This day is when the most orders were placed. select data from orders_sqoop

select * from orders_sqoop where order_date in (select x.order_date from (select order_date, count(order_id) as total_orders from orders_sqoop group by order_date order by total_orders desc limit 1) as x);

=================================================================================
11. query table in impala that shows all orders belonging to a certain day. This day is when the most orders were placed. select data from orders_sqoop
=================================================================================